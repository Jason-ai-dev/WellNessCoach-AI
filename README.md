Project Title:
Pete: A Mindful Companion

Authors:
Simon Pislar, Supun Madusanka, Barath Chandra, Jason El Ghorayeb

Date:
17 January 2025

Objectives (High-Level Goals)
1.	Emotion Detection Capability:
Develop an intelligent system to detect and interpret users’ emotions based on voice tone and facial expressions with a focus on accuracy and responsiveness.
2.	Multi-user Interaction:
Enable Furhat to seamlessly engage with at least two users simultaneously, identifying and responding to their unique emotional states without confusion.
3.	Adaptive Conversational Skills:
Equip Furhat with the ability to respond dynamically to users’ emotions, adjusting its tone, expressions, and conversational content to create a personalized and empathetic interaction.
4.	Wellness Advice Generation:
Design Furhat to offer actionable and practical advice regarding fitness, mental health, lifestyle, and meal planning, tailored to individual emotional states and contextual needs.
5.	Memory Integration:
Incorporate a memory feature that allows Furhat to recognize returning users, recall previous interactions, and build a long-term relationship through personalized dialogues.
6.	User-friendly Accessibility:
Create a user interface that is intuitive, easy to use, and accessible to a diverse audience, including non-technical users.
________________________________________
Success Metrics
1.	Emotion Detection:
o	Achieve at least 85% accuracy in detecting emotions based on facial expressions and voice tone during testing.
o	Validate successful detection in low-light and noisy environments.
2.	Multi-user Functionality:
o	Demonstrate Furhat’s ability to distinguish and process emotional states from at least two simultaneous users without mixing inputs.
3.	Adaptability:
o	Ensure Furhat adjusts its responses to user emotions in at least 90% of test cases during prototype trials.
4.	Advice Effectiveness:
o	Conduct user surveys to confirm that >80% of users find the wellness advice relevant and helpful.
5.	Memory Implementation:
o	Validate Furhat’s ability to recognize and recall at least 90% of returning users and adapt conversations accordingly.
6.	UI Accessibility:
o	Gather feedback from a user group to achieve at least 90% satisfaction with the UI design in terms of usability and simplicity.
________________________________________
Potential Issues
1.	Emotion Detection:
o	Difficulty in accurately detecting complex emotions or ambiguous expressions.
o	Misalignment of emotion data between facial expressions and voice tone.
2.	Multi-user Interaction:
o	Challenges in distinguishing and prioritizing inputs from multiple users, especially in noisy settings.
3.	Memory Feature:
o	Potential for data storage/privacy concerns related to remembering user interactions.
o	Managing scalability as the memory database grows with repeated interactions.
4.	Real-time Processing:
o	Ensuring Furhat processes facial, audio, and conversational data in real time without delays, especially when handling multiple users.
5.	Advice Personalization:
o	Risk of generic or irrelevant advice if the system fails to adapt to diverse emotional contexts.
6.	Usability:
o	Balancing simplicity for non-technical users with advanced options for detailed customization.
o	Risk of overwhelming users with too many features or unclear navigation.
________________________________________________________________________________________
Deliverables
1.	User-Friendly Interface:
o	A clean, intuitive, and accessible user interface that allows seamless interaction with Furhat, suitable for both technical and non-technical users.
2.	Emotion Detection System:
o	A robust subsystem capable of detecting emotions in real-time from both facial expressions and voice tone.
o	Capability to handle inputs from at least two users simultaneously with minimal errors.
3.	Adaptive Robot Responses:
o	Furhat should generate appropriate and empathetic responses tailored to users' emotional states, ensuring engaging and context-sensitive interactions.
4.	Wellness and Lifestyle Advice:
o	A built-in functionality where Furhat provides advice related to fitness, mental health, lifestyle, and meal planning based on user emotional and conversational contexts.
5.	Multi-user Support:
o	Ensure Furhat can distinguish between and interact with two or more users during the same session, dynamically adapting to their respective inputs.
6.	Memory Functionality:
o	Implement a memory system where Furhat can recognize returning users, recall prior interactions, and maintain a personalized dialogue history.
7.	Real-Time Feedback Loop:
o	A system that integrates real-time emotional input (via webcam and audio) with adaptive conversation, demonstrating smooth and timely responses.
8.	Comprehensive Documentation and Presentation:
o	Include written documentation describing:
	Technical details of the User Perception and Interaction subsystems.
	How the system detects emotions and generates responses.
	Ethical considerations for user memory and privacy.
o	Deliver a final presentation showcasing Furhat’s functionality, user interaction scenarios, and real-world applications.

